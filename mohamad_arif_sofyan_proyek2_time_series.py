# -*- coding: utf-8 -*-
"""Mohamad Arif Sofyan_Proyek2-Time Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KsmygWP3axylXbyhinC8BB-aZOPBQbik
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Import Package"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

"""# Import Data"""

df = pd.read_csv("/content/drive/MyDrive/Dicoding/PENGEMBANGAN MACHINE LEARNING/PROYEK2 - TIME SERIES/testset.csv")
df.head()

df.shape

# Memilih kolom yang diinginkan
df = df[['datetime_utc', ' _tempm']]
df.head()

# Mengubah nama kolom
df = df.rename(columns={'datetime_utc': 'date', ' _tempm': 'temp'})
df.head()

df.info()

# Mengubah kolom 'date' menjadi tipe data datetime
df['date'] = pd.to_datetime(df['date'], format='%Y%m%d-%H:%M')

# Menjadikan kolom 'date' sebagai indeks
df = df.set_index('date')
df.head()

# Plot data
plt.figure(figsize=(15, 5))
plt.plot(df.index, df['temp'], label='Temperature')
plt.title('Temperature Time Series')
plt.xlabel('Date')
plt.ylabel('Temperature')
plt.legend()
plt.show()

"""# Resampling dan Imputasi Missing Values"""

# Resample data menjadi skala harian dan mengambil rata-rata
df_daily = df.resample('D').mean()
df.head()

# Cek missing values
df_daily.isna().sum()

# Mengisi missing values dengan nilai rata-rata mingguan
df_daily['temp'].fillna(df_daily['temp'].mean(), inplace=True)

# Plot data
plt.figure(figsize=(15, 5))
plt.plot(df_daily.index, df_daily['temp'], label='Temperature')
plt.title('Temperature Time Series')
plt.xlabel('Date')
plt.ylabel('Temperature')
plt.legend()
plt.show()

"""# Normalisasi Data"""

scaler = MinMaxScaler()
temp_scaled = scaler.fit_transform(df_daily)

# Mempersiapkan data untuk model
temp_scaled = np.array(temp_scaled).reshape(-1)

temp_scaled

"""# Membagi Data Menjadi Training dan Validation Set"""

train_data, test_data = train_test_split(temp_scaled, test_size=0.2, shuffle=False)
train_data.shape, test_data.shape

"""# Mempersiapkan Dataset Windowed"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
    series = tf.expand_dims(series, axis=-1)
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(window_size + 1))
    ds = ds.shuffle(shuffle_buffer)
    ds = ds.map(lambda w: (w[:-1], w[-1:]))
    return ds.batch(batch_size).prefetch(1)

# Menetapkan parameter dataset
window_size = 60
batch_size = 32
shuffle_buffer = 1000

# Mempersiapkan dataset untuk training dan testing
train_set = windowed_dataset(train_data, window_size, batch_size, shuffle_buffer)
test_set = windowed_dataset(test_data, window_size, batch_size, shuffle_buffer)

"""# Membangun Model LSTM"""

# Membangun model LSTM
model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=[None, 1]),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(30, activation="relu"),
    tf.keras.layers.Dense(10, activation="relu"),
    tf.keras.layers.Dense(1),
])

# Menggunakan optimizer dengan learning rate yang disesuaikan
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=["mae"])

"""# Melatih Model"""

# Callback untuk menghentikan training ketika sudah cukup baik
callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)

# Train the model
history = model.fit(
    train_set,
    epochs=100,
    validation_data=test_set,
    callbacks=[callback]
)

"""# Visualisasi Hasil Training"""

# Visualisasi Loss Training dan Validation
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# Evaluasi Model"""

# Evaluasi model pada data test
mae_test = model.evaluate(test_set)[1]

# Perhitungan threshold MAE
threshold_mae = (df_daily['temp'].max() - df_daily['temp'].min()) * 0.1

print(f"MAE pada data test: {mae_test}")
print(f"Threshold MAE (10% dari skala data): {threshold_mae}")

# Cek apakah MAE model < 10% skala data
if mae_test < threshold_mae:
    print("Model berhasil memenuhi kriteria MAE < 10% skala data.")
else:
    print("Model tidak memenuhi kriteria MAE < 10% skala data.")